{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%env SAVE_PATH=../data/uzbek_ner.json",
   "id": "d18d7a1fad0e9397"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "from datasets import load_dataset\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ],
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"risqaliyevds/uzbek_ner\", split=\"train\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T08:49:49.492565800Z",
     "start_time": "2024-05-28T08:49:45.818850700Z"
    }
   },
   "id": "a7b1039f729726dc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "ners_tags = [\n",
    "    \"LOC\",\n",
    "    \"ORG\",\n",
    "    \"PERSON\",\n",
    "    \"DATE\",\n",
    "    \"MONEY\",\n",
    "    \"PERCENT\",\n",
    "    \"QUANTITY\",\n",
    "    \"TIME\",\n",
    "    \"PRODUCT\",\n",
    "    \"EVENT\",\n",
    "    \"WORK_OF_ART\",\n",
    "    \"LANGUAGE\",\n",
    "    \"CARDINAL\",\n",
    "    \"ORDINAL\",\n",
    "    \"NORP\",\n",
    "    \"FACILITY\",\n",
    "    \"LAW\",\n",
    "    \"GPE\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T08:49:49.507652400Z",
     "start_time": "2024-05-28T08:49:49.491539100Z"
    }
   },
   "id": "d3ef36a7f54d91e6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_loc_ner(text, ner):\n",
    "    \"\"\"\n",
    "    Find the position of ner in the text.\n",
    "    Returns the start and end positions of the ner.\n",
    "    \"\"\"\n",
    "    start = text.find(ner)\n",
    "    end = start + len(ner) if start != -1 else -1\n",
    "    return start, end\n",
    "\n",
    "\n",
    "def extract_named_entities(data, ners_tags):\n",
    "    \"\"\"\n",
    "    Extract named entities from the data and resolve any overlaps.\n",
    "    Returns a list of tuples (start, end, tag) representing the named entities.\n",
    "    \"\"\"\n",
    "    text = data[\"text\"]\n",
    "    new_ner = {}\n",
    "\n",
    "    for tag, values in data[\"ner\"].items():\n",
    "        if tag in ners_tags and values:\n",
    "            for value in values:\n",
    "                start, end = get_loc_ner(text, value)\n",
    "                if start != -1:  # Ensure valid positions\n",
    "                    new_ner[(start, end)] = tag\n",
    "\n",
    "    new_ner_list = resolve_overlaps(new_ner)\n",
    "    return new_ner_list\n",
    "\n",
    "\n",
    "def resolve_overlaps(new_ner):\n",
    "    \"\"\"\n",
    "    Resolve overlapping named entities, keeping the longest one.\n",
    "    Returns a list of tuples (start, end, tag) representing the named entities.\n",
    "    \"\"\"\n",
    "    new_ner_list = []\n",
    "\n",
    "    for key in new_ner.keys():\n",
    "        start, end = key\n",
    "        tag = new_ner[key]\n",
    "        if len(new_ner_list) == 0:\n",
    "            new_ner_list.append((start, end, tag))\n",
    "        else:\n",
    "            is_intersection = False\n",
    "            for i in range(len(new_ner_list)):\n",
    "                s, e, t = new_ner_list[i]\n",
    "                if (start >= s and start <= e) or (end >= s and end <= e):\n",
    "                    is_intersection = True\n",
    "                    if end - start > e - s:\n",
    "                        new_ner_list[i] = (start, end, tag)\n",
    "            if not is_intersection:\n",
    "                new_ner_list.append((start, end, tag))\n",
    "\n",
    "    return new_ner_list\n",
    "\n",
    "\n",
    "def get_labeled_list(chunk):\n",
    "    chunk_ = deepcopy(chunk)\n",
    "\n",
    "    text = chunk_[\"text\"]\n",
    "    words = text.split(\" \")\n",
    "\n",
    "    entities = extract_named_entities(chunk_, ners_tags)\n",
    "    labels = [\"O\"] * len(words)\n",
    "\n",
    "    for start, end, tag in entities:\n",
    "        entity_text = text[start:end]\n",
    "        entity_words = entity_text.split(\" \")\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            word_start = text.find(word, 0 if i == 0 else text.find(words[i - 1]) + len(words[i - 1]) + 1)\n",
    "            word_end = word_start + len(word)\n",
    "\n",
    "            if word_start >= start and word_end <= end:\n",
    "                if i == 0 or labels[i - 1] == \"O\":\n",
    "                    labels[i] = f\"B-{tag}\"\n",
    "                else:\n",
    "                    labels[i] = f\"I-{tag}\"\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def make_dataset(dataset):\n",
    "    labeled_dataset = []\n",
    "\n",
    "    for chunk in tqdm(dataset):\n",
    "        labels = get_labeled_list(chunk)\n",
    "        labeled_dataset.append({\n",
    "            \"text\": chunk[\"text\"],\n",
    "            \"labels\": labels\n",
    "        })\n",
    "\n",
    "    return labeled_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T08:49:50.344041700Z",
     "start_time": "2024-05-28T08:49:50.299074300Z"
    }
   },
   "id": "84dfefb76ccb3f47"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 19609/19609 [00:04<00:00, 4138.86it/s]\n"
     ]
    }
   ],
   "source": [
    "labeled_dataset = make_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T08:50:00.968582500Z",
     "start_time": "2024-05-28T08:49:56.206538800Z"
    }
   },
   "id": "9cbada44db435602"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Shvetsiya hukumati Stokholmdagi asosiy piyodalar ko‘chasi Drottninggatanda odamlar ustiga yuk mashinasini haydab borgani gumon qilinayotgan shaxsni qo‘lga oldi. Bu haqda Expressen TV efirida Shvetsiya bosh vaziri Stefan Lyoven ma'lum qildi. Ushbu shaxs surati ijtimoiy tarmoqda tarqalmoqda. U Spendrups kompaniyasiga tegishli yuk mashinasini o‘g‘irlagani aytilmoqda.   Oxirgi ma'lumotlarga ko‘ra, ushbu hujum oqibatida halok bo‘lganlar soni 5 nafarga yetdi, jarohatlanganlar soni aniq emas.\", 'labels': ['B-GPE', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GPE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(labeled_dataset[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T08:50:04.042633600Z",
     "start_time": "2024-05-28T08:50:03.974003900Z"
    }
   },
   "id": "4f57aabb5daf1cf0"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "save_path = os.environ[\"SAVE_PATH\"]\n",
    "\n",
    "import json\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(labeled_dataset, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T09:04:20.432436500Z",
     "start_time": "2024-05-28T09:04:19.926845100Z"
    }
   },
   "id": "956dab43bcd387df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
